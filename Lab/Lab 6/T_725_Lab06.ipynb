{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaOv_zTbtjbY"
      },
      "source": [
        "# T-725 Natural Language Processing: Lab 6\n",
        "In today's lab, we will be working with the SHAP and Transformers libraries for explainability and debugging bias.\n",
        "\n",
        "To begin with, do the following:\n",
        "* Select `\"File\" > \"Save a copy in Drive\"` to create a local copy of this notebook that you can edit.\n",
        "* **Select `\"Runtime\" > \"Change runtime type\"`, and make sure that you have \"Hardware accelerator\" set to \"GPU\"**\n",
        "\n",
        "All examples are taken from the [SHAP](https://shap.readthedocs.io/en/stable/index.html) website.\n",
        "\n",
        "Install the required libraries and then **restart the runtime**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2PVHdnIdb8u"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w3n9ub8djs8"
      },
      "outputs": [],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KozT98-3rgWz"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5_mWjh03qoc"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fACD8OWQunwL"
      },
      "source": [
        "##SHAP (SHapley Additive exPlanations)\n",
        "\n",
        "SHAP is a method for understanding how much each feature contributes to a model’s prediction. The idea comes from game theory: we treat the model’s prediction as the value of a game and the features as players. Just like in a cooperative game, we want to know how to fairly divide the “credit” for the outcome among all the players (see [papers](https://github.com/slundberg/shap#citations) for details and citations).\n",
        "\n",
        "The Shapley value solves this by looking at all possible ways the players could join the game. For each order, we measure how much the prediction changes when a feature is added to the group of features that are already there. Then we average these contributions across every possible order of joining. This gives us a fair and consistent measure of how important each feature really was.\n",
        "\n",
        "In machine learning, this means we compare predictions made with different subsets of features. We ask: if we already know some features, how much does adding one more feature change the model’s prediction? By averaging these changes across all combinations, we get the SHAP value for that feature.\n",
        "\n",
        "The result is that every prediction can be broken down into a baseline value (usually the average prediction when no features are known) plus the contributions of each feature. SHAP guarantees that these contributions add up exactly to the final prediction. Unlike simpler importance measures, SHAP values satisfy fairness principles: features with the same effect get the same credit, irrelevant features get none, and the whole explanation is consistent across models.\n",
        "\n",
        "In short, SHAP provides a principled and fair way to explain complex machine learning models by showing how much each feature pushed a specific prediction up or down."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJwbP2wxxBR0"
      },
      "source": [
        "##Emotion classification multiclass example\n",
        "\n",
        "This section demonstrates how to use the `Partition` explainer for a multiclass text classification scenario. Once the SHAP values are computed for a set of sentences we then visualize feature attributions towards individual classes. The text classifcation model we use is BERT fine-tuned on an emotion dataset to classify a sentence among six classes: *joy*, *sadness*, *anger*, *fear*, *love* and *surprise*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkEJxthUxSyw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDT--tAYxVeJ"
      },
      "outputs": [],
      "source": [
        "# load the emotion dataset\n",
        "dataset  = datasets.load_dataset(\"emotion\", split = \"train\")\n",
        "data = pd.DataFrame({'text':dataset['text'],'emotion':dataset['label']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuIK9kssyZjK"
      },
      "source": [
        "###Build a transformers pipline\n",
        "\n",
        "Note that we have set `return_all_scores=True` for the pipeline so we can observe the model's behavior for all classes, not just the top output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IgayMGzxVYB"
      },
      "outputs": [],
      "source": [
        "# load the model and tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"nateraw/bert-base-uncased-emotion\", use_fast=True)\n",
        "emotion_model = transformers.AutoModelForSequenceClassification.from_pretrained(\"nateraw/bert-base-uncased-emotion\").cuda()\n",
        "\n",
        "# build a pipeline object to do predictions\n",
        "prediction_pipe = transformers.pipeline(\"text-classification\", model=emotion_model, tokenizer=tokenizer, device=0, return_all_scores=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YYl8h9vyneo"
      },
      "source": [
        "###Create an explainer for the pipeline\n",
        "\n",
        "A transformers `pipeline` object can be passed directly to `shap.Explainer`, which will then wrap the pipeline model as a `shap.models.TransformersPipeline` model and the pipeline tokenizer as a `shap.maskers.Text masker`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFddLZq-yuAH"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(prediction_pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moakPAgKyzLr"
      },
      "source": [
        "###Compute SHAP values\n",
        "\n",
        "Explainers have the same method signature as the models they are explaining, so we just pass a list of strings for which to explain the classifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSD_FUb9yuz0"
      },
      "outputs": [],
      "source": [
        "shap_values = explainer(data['text'][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7HplLUvy_fB"
      },
      "source": [
        "###Visualize the impact on all the output classes\n",
        "\n",
        "In the plots below, when you hover your mouse over an output class you get the explanation for that output class. When you click an output class name then that class remains the focus of the explanation visualization until you click another class.\n",
        "\n",
        "The base value is what the model outputs when the entire input text is masked, while $f_{outputclass}=(inputs)$\n",
        "is the output of the model for the full original input. The SHAP values explain in an addive way how the impact of unmasking each word changes the model output from the base value (where the entire input is masked) to the final prediction value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vec75vfey_8H"
      },
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjEc4xyH04jn"
      },
      "source": [
        "###Visualize the impact on a single class\n",
        "\n",
        "Since `Explanation` objects are sliceable we can slice out just a single output class to visualize the model output towards that class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6CccbU-yuwa"
      },
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values[:, :, \"anger\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3FXs2kO0-Fx"
      },
      "source": [
        "###Plotting the top words impacting a specific class\n",
        "\n",
        "In addition to slicing, `Explanation` objects also support a set of reducing methods. Here we use the `.mean(0)` to take the average impact of all words towards the “joy” class. Note that here we are also averaging over three examples, to get a better summary you would want to use a larger portion of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFsPogkf1NAn"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values[:,:,\"joy\"].mean(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgdPVUqq1M2n"
      },
      "outputs": [],
      "source": [
        "# we can sort the bar chart in decending order\n",
        "shap.plots.bar(shap_values[:,:,\"joy\"].mean(0), order=shap.Explanation.argsort)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZPsgbbk0-DR"
      },
      "source": [
        "##Machine Translation Explanations\n",
        "This section demonstrates model explanations for a text to text scenario using a pretrained transformer model for machine translation. In this demo, we showcase explanations on a model for [English to French](https://huggingface.co/Helsinki-NLP/opus-mt-en-fr)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa1YhVwzgHaK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import shap\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGnj9FgnfAHZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SVhAuW3jztN"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"Transformers have rapidly become the model of choice for NLP problems, replacing older recurrent neural network models\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rviJj_98ht9A"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(translation_model, tokenizer)\n",
        "shap_values = explainer(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-2UPLDE4ht1o"
      },
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qOY-F61OYgB"
      },
      "source": [
        "Note that we can do the same thing with other languages. The [Helsinki NLP](https://huggingface.co/Helsinki-NLP) group, for example, has models in multiple other languages you can try out, such as for Icelandic to English (Helsinki-NLP/opus-mt-is-en) and vice versa (Helsinki-NLP/opus-mt-en-is)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_W3qZ4n3W27"
      },
      "source": [
        "##Open Ended GPT2 Text Generation Explanations\n",
        "This section shows how to get explanations for the output of GPT2 used for open ended text generation. In this demo, we use the pretrained GPT2 model provided by [Hugging Face](https://huggingface.co/gpt2) to explain the generated text by GPT2. We further showcase how to get explanations for custom output generated text and plot global input token importances for any output generated token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFyJiVDv5TET"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import shap\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYVxUwiD5Yyq"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
        "nlg_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukIILGDT5ddS"
      },
      "source": [
        "Below, we set certain model configurations. We need to define if the model is a decoder or encoder-decoder. This can be set through the ‘is_decoder’ or ‘is_encoder_decoder’ param in model’s config file. We can also set custom model generation parameters which will be used during the output text generation decoding process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE2o6ffe5eLG"
      },
      "outputs": [],
      "source": [
        "# set model decoder to true\n",
        "nlg_model.config.is_decoder=True\n",
        "# set text-generation params under task_specific_params\n",
        "nlg_model.config.task_specific_params[\"text-generation\"] = {\n",
        "    \"do_sample\": True,\n",
        "    \"max_length\": 50,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_k\": 50,\n",
        "    \"no_repeat_ngram_size\": 2\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI-lTm_H5lyU"
      },
      "source": [
        "Define initial text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1v6eVV55h1C"
      },
      "outputs": [],
      "source": [
        "s = ['I enjoy walking with my cute dog']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkG7qqIS5sjZ"
      },
      "source": [
        "Create an explainer object and compute the SHAP values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJMQTvDS5wzy"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(nlg_model, tokenizer)\n",
        "shap_values = explainer(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "599tt7gi51GX"
      },
      "source": [
        "Visualize shap explanations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTkAkLcp5ynn"
      },
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHWbaFH_5SdK"
      },
      "source": [
        "###Custom text generation and debugging biased outputs\n",
        "Below we demonstrate the process of how to explain the liklihood of generating a particular output sentence given an input sentence using the model. For example, we ask a question: Which country's inhabitant (target) in the sentence \"I know many people who are [target].\" would have a high liklilhood of generating the token \"vodka\" in the output sentence \"They love their vodka!\"? For this, we first define input-output sentence pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSslfFN06khi"
      },
      "outputs": [],
      "source": [
        "# define input\n",
        "x = [\n",
        "    \"I know many people who are Finnish.\",\n",
        "    \"I know many people who are Greek.\",\n",
        "    \"I know many people who are Australian.\",\n",
        "    \"I know many people who are American.\",\n",
        "    \"I know many people who are Italian.\",\n",
        "    \"I know many people who are Spanish.\",\n",
        "    \"I know many people who are German.\",\n",
        "    \"I know many people who are Indian.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICDFRPBl6pTC"
      },
      "outputs": [],
      "source": [
        "# define output\n",
        "y = [\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mZGgryk6wUp"
      },
      "source": [
        "We wrap the model with a Teacher Forcing scoring class and create a Text masker:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7rhBS8B6y4Q"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_model = shap.models.TeacherForcing(nlg_model, tokenizer)\n",
        "masker = shap.maskers.Text(tokenizer, mask_token = \"...\", collapse_mask_token=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y1eESxk7Sr7"
      },
      "source": [
        "Create an explainer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mWOZZun7Uii"
      },
      "outputs": [],
      "source": [
        "explainer = shap.Explainer(teacher_forcing_model, masker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7lm-o4O7Wzx"
      },
      "source": [
        "Generate SHAP explanation values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMIDTCnj7ZKw"
      },
      "outputs": [],
      "source": [
        "shap_values = explainer(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3vuPjiA7dDI"
      },
      "source": [
        "Now that we have generated the SHAP values, we can have a look at the contribution of tokens in the input driving the token \"vodka\" in the output sentence using the text plot. Just hover your mouse over \"vodka\" to see this for each example. You can also click on the word \"vodka\" to see this more clearsly.\n",
        "\n",
        "Note: The red color indicates a positive contribution while the blue color indicates negative contribution and the intensity of the color shows its strength in the respective direction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "0dx-BnDb7jfg"
      },
      "outputs": [],
      "source": [
        "shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heV0SNz_6lR6"
      },
      "source": [
        "That's it! Now you can gain better insight into your models using SHAP 😀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj0hiGUD7-cQ"
      },
      "source": [
        "##Assignment\n",
        "\n",
        "Complete the following questions and hand in your solution in Canvas before 23:59 Friday, October 4th. Remember to save your file before uploading it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv9-q5ZYW6PJ"
      },
      "source": [
        "##Part 1\n",
        "\n",
        "Visualize the relation of the input to the emotions.\n",
        "\n",
        "Which words impact each class the most?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bcPxADKYBDH"
      },
      "outputs": [],
      "source": [
        "green_mile = [\"\",\"\"\"\n",
        "I want it over and done. I do. I'm tired, boss. Tired of bein' on the road, lonely\n",
        "as a sparrow in the rain. Tired of not ever having me a buddy to be with, or tell\n",
        "me where we's coming from or going to, or why. Mostly I'm tired of people being\n",
        "ugly to each other. I'm tired of all the pain I feel and hear in the world everyday.\n",
        "There's too much of it. It's like pieces of glass in my head all the time. Can you\n",
        "understand?\n",
        "\"\"\",\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B86vFs1aW597"
      },
      "outputs": [],
      "source": [
        "# Your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixGF3oS08CWg"
      },
      "source": [
        "##Part 2\n",
        "\n",
        "Visualize the explanations for machine translation models for two languages you speak or have the best knowledge of. Try running this for three different sentences.\n",
        "\n",
        "Does the output sequence correlate with the input sequence in a way you would have expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP5rEz9h9ONn"
      },
      "outputs": [],
      "source": [
        "# Your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AigAZRH4VjuY"
      },
      "source": [
        "##Part 3\n",
        "\n",
        "Use the method to debug biased output on a different kind of bias. For example, gender bias related to professions like doctors.\n",
        "\n",
        "Try one more example of your choosing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwnwmXDaWKFR"
      },
      "outputs": [],
      "source": [
        "# Solution to gender bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTgeKCl1WNcq"
      },
      "outputs": [],
      "source": [
        "# Solution to your own example"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}